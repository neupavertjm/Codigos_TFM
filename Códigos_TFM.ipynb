{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install praw langdetect pandas openpyxl spacy docx\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qaaFslFOyk2",
        "outputId": "703591ea-8783-4935-e639-4a156caa6d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praw\n",
            "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Collecting docx\n",
            "  Downloading docx-0.2.4.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting prawcore<3,>=2.4 (from praw)\n",
            "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting update_checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from docx) (5.4.0)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.11/dist-packages (from docx) (11.2.1)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
            "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Building wheels for collected packages: langdetect, docx\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=b1ded01961032308aceb71bc9755aa5e634937cdd27771970191dbbc4bc0bf0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "  Building wheel for docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx: filename=docx-0.2.4-py3-none-any.whl size=53893 sha256=4a9e62cb2362ab1c2ea03a85d4f31317d3201ba57734586a24242cd7ad544156\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/3e/c3/e81c11effd0be5658a035947c66792dd993bcff317eae0e1ed\n",
            "Successfully built langdetect docx\n",
            "Installing collected packages: langdetect, docx, update_checker, prawcore, praw\n",
            "Successfully installed docx-0.2.4 langdetect-1.0.9 praw-7.8.1 prawcore-2.4.0 update_checker-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "from langdetect import detect, DetectorFactory\n",
        "import time\n",
        "\n",
        "# Asegurar detecciÃ³n de idioma consistente\n",
        "DetectorFactory.seed = 0\n",
        "\n",
        "# ConfiguraciÃ³n de Reddit\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"u1MiQwZVrUKVb_LQzmg5yA\",       # Reemplaza con tu Client ID\n",
        "    client_secret=\"mxTNHZmHG5Yb6pPgZPpi9PWFqux0pQ\",   # Reemplaza con tu Client Secret\n",
        "    user_agent=\"script para TFM v1.0 by neupavertjm\"\n",
        ")\n",
        "\n",
        "reddit.read_only = True  # Solo lectura\n",
        "\n",
        "# Inputs del usuario\n",
        "keywords = input(\"Introduce las palabras clave (separadas por comas): \").split(\",\")\n",
        "keywords = [kw.strip().lower() for kw in keywords]\n",
        "\n",
        "target_language = input(\"Introduce el cÃ³digo del idioma (ejemplo: 'es' para espaÃ±ol): \").strip().lower()\n",
        "\n",
        "# Subreddits de videojuegos\n",
        "video_game_subreddits = [\"leagueoflegends\", \"VALORANT\", \"GlobalOffensive\",\"csgo\", \"cs2\"]\n",
        "\n",
        "# TÃ©rminos gamer extra (para refinar bÃºsqueda)\n",
        "game_terms = [\"game\", \"gaming\", \"gamer\", \"fps\", \"mmorpg\", \"multiplayer\", \"patch\", \"nerf\", \"buff\", \"ranked\", \"skin\", \"map\",\"flash\",\"feed\"]\n",
        "\n",
        "print(\"\\nğŸ® Buscando posts en subreddits de videojuegos...\\n\")\n",
        "found_posts = 0\n",
        "\n",
        "# Buscar en cada subreddit\n",
        "for sub in video_game_subreddits:\n",
        "    subreddit = reddit.subreddit(sub)\n",
        "    print(f\"ğŸ” Explorando r/{sub}...\\n\")\n",
        "\n",
        "    for submission in subreddit.search(\" \".join(keywords + game_terms), limit=50, sort='new', syntax='lucene'):\n",
        "        try:\n",
        "            text = submission.title + \" \" + submission.selftext\n",
        "            detected_lang = detect(text)\n",
        "\n",
        "            # âœ… Filtrar por idioma, palabra clave del input y tÃ©rminos gamer\n",
        "            if (\n",
        "                detected_lang == target_language and\n",
        "                any(kw in text.lower() for kw in keywords) and\n",
        "                any(term in text.lower() for term in game_terms)\n",
        "            ):\n",
        "                found_posts += 1\n",
        "                print(f\"ğŸ“Œ TÃ­tulo: {submission.title}\")\n",
        "                print(f\"ğŸ”— URL: {submission.url}\")\n",
        "                print(f\"ğŸ—£ï¸ Idioma detectado: {detected_lang}\\n\")\n",
        "\n",
        "            time.sleep(1)  # Evitar rate limit\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Error en post: {e}\")\n",
        "            continue\n",
        "\n",
        "if found_posts == 0:\n",
        "    print(\"âŒ No se encontraron posts en el idioma seleccionado y relacionados con videojuegos.\")\n",
        "\n",
        "print(\"\\nâœ… BÃºsqueda finalizada.\")\n"
      ],
      "metadata": {
        "id": "NF6HhWBGpjZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Etiquetado de las categorÃ­as linguisticas de cada tÃ©rmino. En este caso se optÃ³ por hacer un cÃ³digo, pero siempre revisado por el autor de la investigaciÃ³n.\n",
        "import spacy\n",
        "import json\n",
        "import csv\n",
        "from collections import Counter\n",
        "\n",
        "# Cargar el modelo de spaCy en espaÃ±ol\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "\n",
        "# Leer el JSON con \"TÃ©rmino en espaÃ±ol\", \"TÃ©rmino en inglÃ©s\" y \"DefiniciÃ³n\"\n",
        "with open(\"terminos.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    datos = json.load(f)\n",
        "\n",
        "# Diccionario para traducir etiquetas POS al espaÃ±ol\n",
        "etiquetas = {\n",
        "    \"NOUN\": \"sustantivo\",\n",
        "    \"VERB\": \"verbo\",\n",
        "    \"ADJ\": \"adjetivo\",\n",
        "    \"ADV\": \"adverbio\"\n",
        "}\n",
        "\n",
        "# Diccionario de tÃ©rminos en inglÃ©s y su categorÃ­a asociada\n",
        "terminos_en_ingles = {\n",
        "    \"gank\": \"verbo\",\n",
        "    \"feed\": \"verbo\",\n",
        "    \"rush\": \"verbo\",\n",
        "    # Agregar mÃ¡s tÃ©rminos en inglÃ©s si es necesario\n",
        "}\n",
        "\n",
        "# Procesar tÃ©rminos\n",
        "resultados = []\n",
        "\n",
        "for entrada in datos:\n",
        "    termino_es = entrada.get(\"TÃ©rmino en espaÃ±ol\", \"\").strip()\n",
        "    termino_en = entrada.get(\"TÃ©rmino en inglÃ©s\", \"\").strip()\n",
        "    definicion = entrada.get(\"DefiniciÃ³n\", \"\").strip()\n",
        "\n",
        "    categoria_principal = None\n",
        "\n",
        "    # Comprobar si el tÃ©rmino en inglÃ©s tiene una categorÃ­a predefinida\n",
        "    if termino_en in terminos_en_ingles:\n",
        "        categoria_principal = terminos_en_ingles[termino_en]\n",
        "    else:\n",
        "        # Procesar el tÃ©rmino en espaÃ±ol usando spaCy\n",
        "        doc = nlp(definicion)\n",
        "        conteo_categorias = Counter()\n",
        "\n",
        "        for token in doc:\n",
        "            if token.pos_ in etiquetas:\n",
        "                conteo_categorias[etiquetas[token.pos_]] += 1\n",
        "\n",
        "        if conteo_categorias:\n",
        "            categoria_principal = conteo_categorias.most_common(1)[0][0]\n",
        "        else:\n",
        "            categoria_principal = \"otra\"\n",
        "\n",
        "    resultados.append({\n",
        "        \"TÃ©rmino en espaÃ±ol\": termino_es,\n",
        "        \"TÃ©rmino en inglÃ©s\": termino_en,\n",
        "        \"DefiniciÃ³n\": definicion,\n",
        "        \"CategorÃ­a lingÃ¼Ã­stica\": categoria_principal\n",
        "    })\n",
        "\n",
        "# Guardar como CSV\n",
        "with open(\"terminos_con_categorias.csv\", \"w\", encoding=\"utf-8\", newline='') as f:\n",
        "    writer = csv.DictWriter(f, fieldnames=[\"TÃ©rmino en espaÃ±ol\", \"TÃ©rmino en inglÃ©s\", \"DefiniciÃ³n\", \"CategorÃ­a lingÃ¼Ã­stica\"])\n",
        "    writer.writeheader()\n",
        "    writer.writerows(resultados)\n",
        "\n",
        "# Mostrar algunos resultados por consola\n",
        "for r in resultados[:10]:\n",
        "    print(f\"{r['TÃ©rmino en espaÃ±ol']} / {r['TÃ©rmino en inglÃ©s']}: {r['CategorÃ­a lingÃ¼Ã­stica']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R86qsRR7ef_o",
        "outputId": "400cf109-ab2a-4bc9-8048-c31befdb6f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OTP / : verbo\n",
            "Mejora / Bufo / : sustantivo\n",
            "Golpeo a Distancia (Desgastar?) / : sustantivo\n",
            "Potenciador (?) / Boost / : sustantivo\n",
            "Draft / : sustantivo\n",
            "Botlane (bot) /linea inferior / : sustantivo\n",
            "Botlane (bot) /linea inferior / : sustantivo\n",
            "Ace / : sustantivo\n",
            "Grupo / FormaciÃ³n / : sustantivo\n",
            "Stunnear / Aturdir / : sustantivo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-docx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "antmSKf0xOlt",
        "outputId": "0f4f345c-ccaf-44f9-87eb-fe01e6fe5176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.1)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m174.1/244.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vY8IjyUmjh_4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}