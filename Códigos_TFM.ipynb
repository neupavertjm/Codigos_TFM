{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install praw langdetect pandas openpyxl spacy docx\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qaaFslFOyk2",
        "outputId": "703591ea-8783-4935-e639-4a156caa6d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praw\n",
            "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Collecting docx\n",
            "  Downloading docx-0.2.4.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting prawcore<3,>=2.4 (from praw)\n",
            "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting update_checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from docx) (5.4.0)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.11/dist-packages (from docx) (11.2.1)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
            "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Building wheels for collected packages: langdetect, docx\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=b1ded01961032308aceb71bc9755aa5e634937cdd27771970191dbbc4bc0bf0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "  Building wheel for docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx: filename=docx-0.2.4-py3-none-any.whl size=53893 sha256=4a9e62cb2362ab1c2ea03a85d4f31317d3201ba57734586a24242cd7ad544156\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/3e/c3/e81c11effd0be5658a035947c66792dd993bcff317eae0e1ed\n",
            "Successfully built langdetect docx\n",
            "Installing collected packages: langdetect, docx, update_checker, prawcore, praw\n",
            "Successfully installed docx-0.2.4 langdetect-1.0.9 praw-7.8.1 prawcore-2.4.0 update_checker-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "from langdetect import detect, DetectorFactory\n",
        "import time\n",
        "\n",
        "# Asegurar detección de idioma consistente\n",
        "DetectorFactory.seed = 0\n",
        "\n",
        "# Configuración de Reddit\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"u1MiQwZVrUKVb_LQzmg5yA\",       # Reemplaza con tu Client ID\n",
        "    client_secret=\"mxTNHZmHG5Yb6pPgZPpi9PWFqux0pQ\",   # Reemplaza con tu Client Secret\n",
        "    user_agent=\"script para TFM v1.0 by neupavertjm\"\n",
        ")\n",
        "\n",
        "reddit.read_only = True  # Solo lectura\n",
        "\n",
        "# Inputs del usuario\n",
        "keywords = input(\"Introduce las palabras clave (separadas por comas): \").split(\",\")\n",
        "keywords = [kw.strip().lower() for kw in keywords]\n",
        "\n",
        "target_language = input(\"Introduce el código del idioma (ejemplo: 'es' para español): \").strip().lower()\n",
        "\n",
        "# Subreddits de videojuegos\n",
        "video_game_subreddits = [\"leagueoflegends\", \"VALORANT\", \"GlobalOffensive\",\"csgo\", \"cs2\"]\n",
        "\n",
        "# Términos gamer extra (para refinar búsqueda)\n",
        "game_terms = [\"game\", \"gaming\", \"gamer\", \"fps\", \"mmorpg\", \"multiplayer\", \"patch\", \"nerf\", \"buff\", \"ranked\", \"skin\", \"map\",\"flash\",\"feed\"]\n",
        "\n",
        "print(\"\\n🎮 Buscando posts en subreddits de videojuegos...\\n\")\n",
        "found_posts = 0\n",
        "\n",
        "# Buscar en cada subreddit\n",
        "for sub in video_game_subreddits:\n",
        "    subreddit = reddit.subreddit(sub)\n",
        "    print(f\"🔍 Explorando r/{sub}...\\n\")\n",
        "\n",
        "    for submission in subreddit.search(\" \".join(keywords + game_terms), limit=50, sort='new', syntax='lucene'):\n",
        "        try:\n",
        "            text = submission.title + \" \" + submission.selftext\n",
        "            detected_lang = detect(text)\n",
        "\n",
        "            # ✅ Filtrar por idioma, palabra clave del input y términos gamer\n",
        "            if (\n",
        "                detected_lang == target_language and\n",
        "                any(kw in text.lower() for kw in keywords) and\n",
        "                any(term in text.lower() for term in game_terms)\n",
        "            ):\n",
        "                found_posts += 1\n",
        "                print(f\"📌 Título: {submission.title}\")\n",
        "                print(f\"🔗 URL: {submission.url}\")\n",
        "                print(f\"🗣️ Idioma detectado: {detected_lang}\\n\")\n",
        "\n",
        "            time.sleep(1)  # Evitar rate limit\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error en post: {e}\")\n",
        "            continue\n",
        "\n",
        "if found_posts == 0:\n",
        "    print(\"❌ No se encontraron posts en el idioma seleccionado y relacionados con videojuegos.\")\n",
        "\n",
        "print(\"\\n✅ Búsqueda finalizada.\")\n"
      ],
      "metadata": {
        "id": "NF6HhWBGpjZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Etiquetado de las categorías linguisticas de cada término. En este caso se optó por hacer un código, pero siempre revisado por el autor de la investigación.\n",
        "import spacy\n",
        "import json\n",
        "import csv\n",
        "from collections import Counter\n",
        "\n",
        "# Cargar el modelo de spaCy en español\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "\n",
        "# Leer el JSON con \"Término en español\", \"Término en inglés\" y \"Definición\"\n",
        "with open(\"terminos.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    datos = json.load(f)\n",
        "\n",
        "# Diccionario para traducir etiquetas POS al español\n",
        "etiquetas = {\n",
        "    \"NOUN\": \"sustantivo\",\n",
        "    \"VERB\": \"verbo\",\n",
        "    \"ADJ\": \"adjetivo\",\n",
        "    \"ADV\": \"adverbio\"\n",
        "}\n",
        "\n",
        "# Diccionario de términos en inglés y su categoría asociada\n",
        "terminos_en_ingles = {\n",
        "    \"gank\": \"verbo\",\n",
        "    \"feed\": \"verbo\",\n",
        "    \"rush\": \"verbo\",\n",
        "    # Agregar más términos en inglés si es necesario\n",
        "}\n",
        "\n",
        "# Procesar términos\n",
        "resultados = []\n",
        "\n",
        "for entrada in datos:\n",
        "    termino_es = entrada.get(\"Término en español\", \"\").strip()\n",
        "    termino_en = entrada.get(\"Término en inglés\", \"\").strip()\n",
        "    definicion = entrada.get(\"Definición\", \"\").strip()\n",
        "\n",
        "    categoria_principal = None\n",
        "\n",
        "    # Comprobar si el término en inglés tiene una categoría predefinida\n",
        "    if termino_en in terminos_en_ingles:\n",
        "        categoria_principal = terminos_en_ingles[termino_en]\n",
        "    else:\n",
        "        # Procesar el término en español usando spaCy\n",
        "        doc = nlp(definicion)\n",
        "        conteo_categorias = Counter()\n",
        "\n",
        "        for token in doc:\n",
        "            if token.pos_ in etiquetas:\n",
        "                conteo_categorias[etiquetas[token.pos_]] += 1\n",
        "\n",
        "        if conteo_categorias:\n",
        "            categoria_principal = conteo_categorias.most_common(1)[0][0]\n",
        "        else:\n",
        "            categoria_principal = \"otra\"\n",
        "\n",
        "    resultados.append({\n",
        "        \"Término en español\": termino_es,\n",
        "        \"Término en inglés\": termino_en,\n",
        "        \"Definición\": definicion,\n",
        "        \"Categoría lingüística\": categoria_principal\n",
        "    })\n",
        "\n",
        "# Guardar como CSV\n",
        "with open(\"terminos_con_categorias.csv\", \"w\", encoding=\"utf-8\", newline='') as f:\n",
        "    writer = csv.DictWriter(f, fieldnames=[\"Término en español\", \"Término en inglés\", \"Definición\", \"Categoría lingüística\"])\n",
        "    writer.writeheader()\n",
        "    writer.writerows(resultados)\n",
        "\n",
        "# Mostrar algunos resultados por consola\n",
        "for r in resultados[:10]:\n",
        "    print(f\"{r['Término en español']} / {r['Término en inglés']}: {r['Categoría lingüística']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R86qsRR7ef_o",
        "outputId": "400cf109-ab2a-4bc9-8048-c31befdb6f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OTP / : verbo\n",
            "Mejora / Bufo / : sustantivo\n",
            "Golpeo a Distancia (Desgastar?) / : sustantivo\n",
            "Potenciador (?) / Boost / : sustantivo\n",
            "Draft / : sustantivo\n",
            "Botlane (bot) /linea inferior / : sustantivo\n",
            "Botlane (bot) /linea inferior / : sustantivo\n",
            "Ace / : sustantivo\n",
            "Grupo / Formación / : sustantivo\n",
            "Stunnear / Aturdir / : sustantivo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-docx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "antmSKf0xOlt",
        "outputId": "0f4f345c-ccaf-44f9-87eb-fe01e6fe5176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.1)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m174.1/244.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vY8IjyUmjh_4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}